\pdfoutput=1

\documentclass{l4proj}
\usepackage{float}
\usepackage{hyperref}
\usepackage{lscape}
\usepackage{rotating}
\usepackage{multirow}
\usepackage{booktabs,caption}
\usepackage[table,xcdraw]{}
\usepackage{wrapfig}
\usepackage[compact]{titlesec} 
\usepackage[table]{xcolor}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{lscape}
\usepackage{rotating}
\usepackage{epstopdf}
\usepackage{hyperref}

%\usepackage{alltt}

%\usepackage{fancyvrb}
%\usepackage{bera}

%
% put any packages here
%

\begin{document}
\title{Are matrix-based or node-link graphs more readable when representing causal relationships for social and health data?}
\author{Kristina Lazarova}
\date{March, 2017}
\maketitle


\begin{abstract}

People who work in the social and health policy sectors make decisions based on causality. Causality is usually visualised by node-link graphs, but matrix-based representations have the potential to show higher performance because of their concise and clear visual representation. However, matrix-based graphs have not been extensively studied in causal relationship visualisation. Therefore, an experimental software was created to test human performance when reading causal relationships in node-link and matrix-based graphs. The web application was implemeted using Node.js, Angular and PostgreSQL. To make a thorough investigation of the factors influencing reading time different sizes, layouts and types of questions were created. The direct and the path question represented two different tasks in the experiment. Response time and correctness of the answer were measured. The results showed that matrix-based graphs outperform node-link representations in direct questions. When path questions were concerned, however, node-link graphs were found to be more readable than matrix-based graphs. The results were discussed in relation to previous research in readability of data visualisations.

\end{abstract}


\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}
I would like to express my sincere thanks to Dr. Helen Purchase for giving me the opportunity to work on this project, for her continuous encouragement, and constructive feedback. Also, I wish to express my gratitude to Dr. Dong-Bach Vo who created the software converting node-link graphs into matrix-based representations. 

\end{abstract}


\educationalconsent
%
%NOTE: if you include the educationalconsent (above) and your project is graded an A then
%      it may be entered in the CS Hall of Fame
%
\tableofcontents
%==============================================================================
\chapter{Literature Review}
\pagenumbering{arabic}

\section{Data Visualisation}

Data visualisation has been described as a technique that makes use of computer-supported, interactive illustrations to deepen human's understanding of a dataset \cite{card1999readings}. Information visualisation (InfoVis) is necessary when dealing with increasingly large and complex data. InfoVis systems are most helpful when a set of data is being explored \cite{fekete2008value}. The value of information visualisation is not in understanding a specific question, it is about developing and deepening one's insights of a set of data \cite{fekete2008value}. Data visualisation is able to facilitate this process because there are a number of cognitive benefits associated with it. A large visual cue that illustrates data becomes a single point of reference for human cognitive processes. Visuals become external cognition helpers in facilitating human memory by providing a bigger working set for analysing data. 

Density of the InfoVis and task difficulty are known to influence human performance \cite{netzel2014comparative}. For instance, following a single path on a graph with one trajectory would require less cognitive effort than performing the same task on a highly dense and complex network. However, the exploration of a representation can convey a better insight into the meaning of the data \cite{al2014information}. Al and colleagues \cite{al2014information} argued that InfoVis has three main roles: communication field, knowledge management mean, and decision support instrument. Furthermore, visual architecture and design applied at company and department levels have been reported to be successful due to the low cognitive burden for visualisation reading \cite{king2016cognitive}.

Thus, data visualisation has been used in a number of fields. For example, it was successfully used in Bank of America Chicago Marathon, which is one of the biggest marathons in the world \cite{hanken2016developing}. Large amounts of live data were gathered to establish some of the main principles of event management information visualisation. The main benefits from these practices are keeping track of the progress of the participants, communicating information between the agencies organising the marathon efficiently, and improving medical preparedness. 

Moreover, astronomical researchers have been suggested to benefit from data visualisation techniques \cite{goodman2012principles}. One such technique is linked views in which a user is able to select, highlight and include or exclude points from display and analysis from various data visualisation dimensions. For example, an important visualisation for astrologists can be an interactive exploration of relationships between data points in statistical graphs and locations in live 3D space. Another instance of beneficial data visualisation is "Geographic Information System" tools which are used in demographics and geography. For example, Engage3D provides the functionality of exploring layers of maps in linked-view systems. 

Inventions in this field have been made continuously in order to improve the visualisations and benefit the target public. For example, a heatmap represents a graphical illustration that evaluates conical distribution values around data points based on a respective data value that has associated respective data point \cite{cardno2014data}. Various implementations of a heatmap were developed and discussed since the original heatmap was created, in order to enable easy future work with heatmaps suited for a particularly needed area.

However, there have been many issues related to Big Data visualisations \cite{gorodov2013analytical}. First, visual noise is the phenomenon of having so many data points on the screen that the user cannot see them as separate points which leads to visibility loss. Second, large images are dependent on the device's resolution abilities. Nevertheless, even if many devices are added together for partial data visualisation to represent a more detailed illustration or a larger amount of data, human perception will eventually reach its limit. Therefore, after a certain point, people will not be able to understand the representations or their analysis. A third problem is information loss which is caused by data filtration and aggregation. These techniques are likely to hide information and mislead people analysing the data. Another problem is High Performance Requirements, especially in dynamic visualisation. In addition, the visualisation might be accompanied by a high rate of image change and lead to people being unable to react to the number of data changes. 

Big Data visualisation method has been suggested  to deal with and alleviate some of the mentioned issues. This is the TreeMap visualisation \cite{gorodov2013analytical} which is a hierarchical way of representing data by rectangles. Some advantages of this method are that the hierarchical matching clearly shows data relations and the extreme outliers are visible. A known  disadvantage is that the data must be hierarchical which makes it unsuitable for examining time patterns, for example. 

Another well-known issue of InfoVis is that sometimes it is challenging for people to understand the meaning of the data. A study aimed to examine familiarity of museum visitors with different visualisation techniques \cite{borner2015investigating}. They included charts, maps, graphs, and networks to reveal how familiar people are with them. It was found that even though most participants were interested in science and art they had difficulties naming and reading the visualisations. It was concluded that people are interested in visualisation techniques, but have significant difficulties in naming and understanding them. 

In order to solve this issue, research has also investigated the way InfoVis novices approach reading data and the methods that can facilitate their learning. A study used sales data to find the barriers for novices when reading iterative visualisation construction and the way they think about visualisation specifications \cite{grammel2010information}. They found that the biggest barriers were interpreting questions into data factors, visual mappings, and understanding the visual representations. It was found that there is a need for instruments that suggest possible visualisations, facilitate help with learning, and are integrated with tool support for the whole analytic process. Furthermore, recent research acknowledged that individual differences between people influence the way they interpret graphical representations \cite{Steichen:2013:UIV:2449396.2449439}. They suggested that visualisation performance can be improved by personalising visuals according to one's needs, abilities and preferences.

Very little is known about the way users understand and read data visualisations and how they interact with different layouts \cite{etemadpour2015perception}. It is interesting to explore if there are layouts which provoke better task performance and better response time. Etemadpour and colleagues \cite{etemadpour2015perception} conducted a research to find out more about performance in similarity based layouts that are generated by multidimensional projections. The results suggested that projection performance is task-dependent and depends on the nature of the data. Therefore, they concluded that the same data layout can have different performance on different tasks and that performance will also be influenced by the characteristics of the data.

\section{Causal Relationships}

Causal relationships are of great interest for scientists who examine the influence of different factors on each other. Particularly, research regarding health, social and behavioural sciences aim to investigate questions about causal rather than associative relationships. With the help of statistical analysis associations among different factors can be inferred. Associations are relationships that can be observed in joint distributions of factors such as regressions and correlations. Causal analysis, in addition, is the practice that aims to infer probabilities under factors that are changing \cite{pearl2010introduction}. These could be, for example, changes influenced by factors such as drinking, childhood issues or applied treatments. 

A study looking to identify factors influencing blog design used the Decision Making Trial and Evaluation Laboratory method (DALMATEL) which is used to illustrate the relationships between factors and allows causal relationships to be shown \cite{hsu2012evaluation}. Some of the causal relationships they found were that colour arrangement directly impacts simplicity of layout and colour arrangement directly impacts font arrangement. 

ReView is a tool for finding causal relationships in anomalies in network traffic. It has been suggested to facilitate a better understanding of network representations \cite{Zhang:2015:VTC:2713579.2713583}. One of its features is minimising the detailed information while showing the causal relationship. ReView can also quickly navigate the user through networks with a large number of requests and levels of abstractions.

Causal relationships are thought to be perceived easier if they are accompanied by animation. Ware and colleagues \cite{ware1999visualizing} followed Michotte's perception of causality principle which illustrates a causal event with a billiard ball hitting another ball and causing its motion. They introduced a visual causal vector method that shows a causal relationship between representations using animation. They found that the perception of causality depends on the simultaneous occurrence the visual causal vector and the change in the graphical representations. Thus, causal relationships have been studied extensively and different visualisations have been created to enable better readability.

\section{Node-Link Graphs}

Node-link graphs consist of nodes which are connected by edges. A large amount of work has been dedicated to visualising those structures in the most readable way. However, the larger the network that is being illustrated, the higher the possibility that the graph becomes dense and unreadable. This is especially true when the direction of the edges is important \cite{dwyer2013edge}. When representing causal relationships with node-link graphs if node n is causing node m, then the edge between these two nodes will point towards node m. In order to avoid the complexity of the large network, some researchers have tried to add interaction with the graph \cite{gansner2005topological}, while others' intention was to create visuals that do not change the structure of the network and does not require interaction \cite{dwyer2013edge}. An innovative interaction technique was designed by Abello and colleagues \cite{abello2006ask} where a user is able to navigate through a hierarchically clustered base of the graph. In the noninteractive technique, researchers decreased the complexity of large directed graphs by replacing single edges with edges which connect to groups of nodes \cite{dwyer2013edge}.  

Nodes have also been used to represent "visual programming language" or workflow and processing functions \cite{thattai2016systems}. The system translates the user input into "a sequence of data language", which is then transformed into "service commands" that are executed. The dependencies between the nodes and data flows are illustrated as interconnections between the vertices on the graphical user interface. 

Well-known structures in node-link visualisations are colliders and confounders. A collider "C" is represented by an "inverted fork", $A->C<-B$ in which the arrow shows a direct link between the tail factors and the head factor \cite{greenland2003quantifying}. Stratifying on the collider is likely to induce a bias and influence the association between A and B. In addition, a similar pattern found in directed acyclic graphs, called a confounder, can be illustrated by a "causal fork" - $A<-C-> B$. Greenland \cite{greenland2003quantifying} suggested that any change in the A-B link upon C-stratification will induce bias. Statistical adjustment for these biases is suggested to lead to as much bias as not making adjustments for them \cite{janszky2010janus}. Thus, colliders and confounders can lead to biases in interpreting InfoVis and these biases are difficult to account for.

Furthermore directed acyclic graphs (DAGs) are increasingly used in representing causal relationships in modern epidemiology \cite{suttorp2015graphical}. The factors in DAGs are connected by arrows which can never create a closed loop \cite{greenland1999causal}. A path is defined by a sequence of arrows between the factors of interest. The DAG method is valuable as it is found to show underlying relations explicitly and easily identifies sources of confounding. A confounding factor is known to be a variable that is related to  the exposure (causing factor) and the outcome (factor being caused) but does not exist in the causal path between them. For example, chronic kidney disease and mortality are often caused by age. Confounding occurs when reading the causal relationships between chronic kidney disease and the outcome mortality. 

Directed node-link graphs are often used to represent causal data. Dense node-link diagrams make reading graphs harder and colliders and confounders are known for inducing reading biases. However, node-link graphs are among the visualisations that do not require extensive learning and are easy and intuitive to read, as they fit the structure of the mental representation they visualise\cite{netzel2014comparative}.

\section{Matrix-based Graphs}

An Adjacency matrix is frequently used to represent a network \cite{longabaugh2012combing}. Matrices can be used to represent both directed and undirected graphs. If a network consists of n nodes, the matrix will consist n x n grid of cells. A new technique called Compressed Adjacency Matrices was introduced in 2012 for visualising gene regulatory networks \cite{dinkla2012compressed}. As those directed networks have specific structural traits, standard representations such as adjacency matrices, and node-link diagrams are unable to depict all traits. Compressed Adjacency Matrices cut and rearrange adjacency matrix so that no space is wasted in case of a sparse network. There are specific structures which represent sub networks. This is how scientists came up with a new data structure in order to fit the characteristics of the data they analyse.

Furthermore, PathwayMatrix is another visualisation tool that represents specific relations between proteins in a pathway \cite{dang2015pathwaymatrix}. The implementation of the tool consists of adjacent matrices that interact with each other. Additional features were added to facilitate the data analysis. This visualisation software received positive feedback in the specific area of representing relations in proteins pathways. Consequently, there is no one best representation technique. Depending on the dataset specifications, the complexity and size of the data there might be many or only a few sufficient ways to visualise it.       

A performance comparison between square and triangular matrices has been conducted to measure performance speed and accuracy \cite{liu2015effects}. It was found that performance is influenced by the matrix juxtaposition type which led to the creation of a new matrix visualisation called TileMatrix. It represents many matrices and is effective at analysing networks that are multi-faceted and time-varying. With TileMatrix it is easy to see differences in matrices across time and facets. However, triangular matrices can work only in non-directed networks. 

On the other hand, some of the disadvantages of matrix-based graphs are that the area increases quadratically and as large networks are sparse there will be mainly empty space on the matrix. Improvements such as compressed adjacency matrix try to account for some of these disadvantages. In general matrix-based representations are considered to be an unambiguous and concise way of representing data. The main advantages of a matrix-based graph are that it has no overlapping and can be ordered.

\section{Node-link vs Matrix-based graphs in causal relationships}

Alper and colleagues \cite{alper2013weighted} compared augmented adjacency matrix with node-link visualisation in brain connectivity by conducting a controlled experiment. Brain connectivity visualisations are in the form of node-link weighted graphs in which each edge is given a numerical weight. It was found that matrix-based graphs outperform node-linked graphs. Alper and colleagues concluded that for weight graphs, node-link representations are less readable and more error-prone when compared to matrices. On the other side, node-link graphs are adjustable to a specific spatial representation which might also be insightful when reading the graph. Overall, matrix-based graphs had higher accuracy.  

Furthermore, it was suggested that adjacency matrices are superior to node-link graphs in representing dense graphs because they are more compact and easier to look at \cite{sheny2007path}. However, they also found that node-link graphs are better for path finding as a path can easily be followed if the arrows are not too tangled. Consequently, as mentioned earlier a unique best InfoVis does not exists. Depending on the data size, data characteristics and question of interest different representations can fit the best performing model. 

Adjacency matrices and node-link diagrams have been compared in another study \cite{keller2006matrices} to examine which is more suitable graphical representation for the general public. This research was provoked by the fact that matrices are mainly used in the engineering area, while node-link graphs are generally a more popular way of visualisation. The research questions being examined were related to the attributes of the connectivity model influencing readability, and which representations were more suitable for the execution of particular tasks. In addition, they filled the gap in previous research that did not take into consideration participants' familiarity with the data sets. It was found that error rates and response time are highly influenced by size and density. They confirmed Ghoniem's \cite{ghoniem2004comparison} findings that matrix-based graphs outperform node-link graphs for dense and large graphs, and node-link graphs are more readable for small and sparse graphs. The only exception found was finding the path between two nodes in a graph. Furthermore, experience with the data set showed to have an effect on performance. 

Ghoniem and colleagues \cite{ghoniem2004comparison} made a performance comparison between node-link and matrix-based graphs. They predicted that counting nodes should be equally difficult in the two types of representations, but counting links and finding the most connected node should be easier in matrix-based representations. Node-link graphs were hypothesised to be better when building a path between two nodes. The reason for this is that matrix based graphs have the nodes represented twice which introduces extra complexity. They also hypothesised that node-link graphs will be easier to work with when dealing with graphs with a few nodes. In their experiment, they had three sizes of graphs - 20, 50, and 100 nodes. They tested 36 participants and measured their performance on various tasks such as finding paths, neighbours, nodes and links between nodes. They found that performance in node-link graphs decreases as the size of the graph increases. This pattern was confirmed for all of the tasks except for finding a path, where node-link graphs regardless of the size and density showed better results.

\chapter{Introduction}

The present research aims to compare and evaluate readability of node-link \ref{drinkingIssuesSmallHierIntro} and matrix-based graphs \ref{gymSmallAlphaintro} when representing causal relationships. As discussed above the two types of representations have already been compared in non-directed networks, but their performance in causal relationships has not been examined yet. Therefore, the aim of this experiment is to investigate whether their readability in directed graphs will be influenced by the same factors as in non-directed visualisations. What is more, deeper knowledge of the difference in their performance can benefit those working in the Social and Health policy sectors. They need an accurate and efficient way of representing data in order to make well-informed and quick decisions. Their decisions are important as they can directly influence social and health policies. In addition, the health and safety sector invests large amounts of money based on their interpretation of causal relationships graphs.


\begin{figure}[H]
\centering
\includegraphics[width=11cm]{images/drinkingIssuesSmallHier.jpg}
\caption{Node-link graph}
\label{drinkingIssuesSmallHierIntro}
\end{figure}

Therefore, knowing which type of causal visualisation has a more efficient and accurate performance will help the health sector make correct and quick decisions. As discussed earlier there can be a best performing visualisation for different types of tasks. Thus, in the present experiment, there are two types of tasks: direct question and path question. The direct questions will be of the type "Depression is caused by which of the following factors", while path questions will require the user to chose a correct causal path from the type "childhood issues $->$ under-aged drinking$->$ depression". 

\begin{figure}[H]
\centering
\includegraphics[width=11cm]{images/gymSmallAlpha.PNG}
\caption{Matrix-based representation}
\label{gymSmallAlphaintro}
\end{figure}
 
To broaden our understanding of the factors that influence readability, graphs' characteristics were manipulated during the experiment. These characteristics included the layout of the graph and its size. As previously mentioned different graph sizes have been associated with better performance in different types of graphs. To conduct an experiment that brings awareness in the topic of interest, an experimental software was implemented. The main functionality of this software is to present experimental questions to the participants and then show their results to the researcher. To measure performance, the software measures time to answer the question, and whether the answer is correct. The results of the experiment showed whether node-link or matrix-based graph is better at representing causal relationships and whether significant performance differences were modulated by factors such as layout and size of the graphs. 

Consequently, the current experiment aims to investigate human performance in readability of causal relationships. These relationships were visualised by node-link graphs and matrix-based representations. A large number of instances of the two types of graphs was generated in order to conduct an experiment and measure participants' performance. Different themes for the graphs were required to prevent learning effects. In addition, the complexity of the data being visualised had to be kept constant. The experimental software had to accommodate these visualisations and their corresponding questions and multiple choice answers. The experiment was run in a controlled environment to ensure participants' performance was not influenced by anything different from the characteristics of the graphs. The response times for the two types of graphs were compared in each size and layout and each type of task. The results of the experiment can enable those working in the Health and Social sector to take faster and better informed decisions. 

\chapter{Implementation details}

\section{Requirements}
\label{Requirements}

A web application was decided to be created to test the proposed research question. This web application was going to be used by participants to give answers to the data visualisation questions and researchers to see the experimental data. Participants were going to see graphs and questions related to them. The participants' response time was to be recorded as well as whether their answer is correct. At the same time, the experimenter had to be able to check the participants' answers to the questions. After considering all requirements, a user story for each feature was created. Some of the most important user stories are:

\begin{itemize}
   \item As a researcher, I want to be able to see participants' answers to all questions, so that I can analyse the data.
   \item As a participant, I want to be able to see a graph and a question at a time, so that I can complete the experiment.
   \item As a researcher, I want to keep participant's scores anonymous, so that the experiment complies with ethics requirements.
   \item As a participant, I want to be unable to go the next question before completing the present question, so that I am certain that I have answered all questions.
   \item As a researcher, I want to be able to see participants' demographic information, so that I can make generalisations about my experiment.
\end{itemize}

\section{Prototype}
After the requirements gathering analysis, development of wire-frames followed. Balsamiq Mockups 3 was the software used for the creation of prototypes. For example, the experimental question page prototype can be found in figure \ref{researchQuestion}.

\begin{figure}[H]
\centering
\includegraphics[width=11cm]{researchQuestion.PNG}
\caption{Experimental Question Prototype}
\label{researchQuestion}
\end{figure}
 
The participants were expected to be unaware of how to read the graphs and, therefore, a training page had to be created. This became apparent only after the revision of the prototype. It was vital to make sure that the participants are aware of how to read each graph before the actual experiment. Therefore, the requirements specification became an iterative process during which a better understanding of the product evolved.

\section{Overview of considered software tools}

To choose the appropriate technologies for this project a research on possible software tools was made. The web application frameworks taken into consideration and the chosen database management system are discussed below. 

\subsection{Spring}

The Java framework Spring was the first considered framework for this project. Spring is among the most widely used frameworks in industry \cite{shiLuiLi}, which implied that the acquired skills from the project would be highly valuable. This decision was also inspired by extensive previous experience with Java from developer's point of view. 

\subsubsection{Challenges}

However, one of the reasons why Spring is used in industry is because of the large and complex systems that exist there. The Spring framework works on a very high level of abstraction where developers can easily write configuration files to add dependencies from different projects. Spring is also considered rather unfriendly for small independent projects like this one and developers with limited Spring experience. This statement was confirmed after issues in setting the relative paths to different CSS and JavaScript files. The problem was found to be in the web application configuration file. However, while fixing this issue Spring was found to be unnecessarily complex and abstract for the implementations of this project.

\subsection{Django}

As a web application framework that is thought in Glasgow University, Django was also considered to be used for the implementation of the web service. Django is a Python-based framework that encourages rapid development. Furthermore, previous experience with the framework might have benefited the development process. However, one of the objectives of this project was to learn new technologies and as Django is already a familiar one, it was disregarded as an option.

\subsection{Node.js}

Node.js was selected on the grounds of being event-driven, non-blocking I/O model which contributes to a very efficient and lightweight software. A Node.js JavaScript engine is used in the Google Chrome browser and has a very good performance \cite{tilkov2010node}. JavaScript servers have incredible performance due to their asynchronous I/O. Node.js appears to be single-threaded from a developer's point of view, as there is no thread management involved in the development process. However, behind the scenes, Node.js handles threading, file system events, implements the event loop, feature thread pooling etc. Coming from a Java background, the Maven equivalent in Node.js was found to be NPM. By using NPM commands the developer is able to install a variety of different modules to help the implementation process. NPM executes the function of a package manager. Express is the standard server framework for Node.js. It is usually described as a minimal and flexible Node.js web application framework. Many popular frameworks such as KeystoneJS, Kraken and Sails, are built on Express. Consequently, the decision to implement the back end of the application with Node.js and JavaScript combined with the Express framework was taken.

\subsection{AngularJS}

AngularJS 1 was chosen for the management of front-end functionality. Even though there is a newer version of the product, the lack of documentation and support on-line, was a sufficient reason for using the older AngularJS. It uses HTML as a template and enables the developers to extend it to express the application's components clearly. AngularJS supports features such as data binding and dependency injection which decreases the amount of code that a developer would usually write to implement them. 

\subsubsection{Challenges}

An interesting issue appeared when combining AngularJS with Node.js. Usually, in AngularJS one uses curly braces to reference data structure from AngularJS controllers. However, Node.js also uses curly brackets to reference information from the back-end in the front-end. This caused a conflict between Angular and Node.js. An Angular error message appeared, but it was not informative enough to convey the reason for the issue. Later, it was found that Node.js overrides the use of curly braces and the application is not displaying Angular data as it expects references from the Node.js back-end, not Angular controllers. Instead of using curly brackets one can also use "ng-bind" and achieve the same result. This approach solved the issue until "ng-bind" information was needed in "ng-src" clause to display the appropriate graph image. It is not possible to use "ng-bind" inside "ng-src" so the found solution at the time was no longer solving the problem. However, as the root of the issue was known, an answer to the question was found and implemented successfully. The Angular configurations had to be altered to use a different symbol for data binding, not the curly brackets. Implementing this solved the problem entirely. 


\subsection{PostgreSQL}

As the size of this project is considerably small a relational database was chosen to be used. PostgreSQL was selected on the basis of being open source and having a reputation of a reliable database system. The database schema looked like this:\newline \textbf{questions} (\underline{question\_id}, question, answer\_one, answer\_two, answer\_three,
		answer\_four, correct, image, type, layout, domain\_question, question\_type) \newline
\textbf{answers}(\underline{question\_id}, \underline{participant\_id}, time, correct) \newline
\textbf{participant\_info}(\underline{participant\_id}, name, email, degree) \newline
\textbf{latin\_square}(\underline{participant\_id}, sequence) \newline

The first table questions had a primary key (PK) question ID, a text field with the actual question, the four multiple choice answers, the correct answer, the image name, type of graph (node-link or matrix-based), the layout, the theme of the graph, and whether it is a direct question or a path question. The answers table consisted of two foreign keys - question ID and participant ID, the time taken to answer the question and whether the answer is correct or not. The participant information table was populated by the demographic questionnaire with participant ID being PK, and name, email and degree the rest of the fields in the table. Latin square was used to randomise the sequence of questions for each participant. More details about Latin square can be found in \autoref{chap:exp}.

\section{System Design}

\begin{figure}[H]
\centering
\includegraphics[width=11.5cm]{abstractDesign.png}
\caption{An abstract representation of the system design}
\label{abstractDesign}
\end{figure}


Figure \ref{abstractDesign} shows an abstract view of the system design. There is an Actor who will either be a participant in the study or a researcher (\autoref{Requirements}). They interact with the front-end which is in the form of a web application in a browser. The front-end communicates with the back-end which was to be implemented in Node.js. The back-end makes requests to the database to retrieve and send information. 

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{moreSpecificDesign.png}
\caption{A more specific representation of the system design}
\label{moreSpecificDesign}
\end{figure}

Figure \ref{moreSpecificDesign} displays a more detailed version of the system design. This design has been implemented to separate the different concerns in this specific system. When the Actor interacts with the application, the front-end sends information to the Controllers. There are as many controllers as pages with front-end functionality in the web application. The Controller component decides what should the next action be according to the user input. It has control over the front-end logic and sends requests to the Service if information from the database or the server is requested. For example, the answers to all questions are kept in the front-end until a "Submit" button is clicked on. This action triggers a request to the Service. The Service component works with the back-end logic. It can send and retrieve data from the database and keep the information in the Repository. Moreover, the Service deals with the requests for the different web pages. It also ensures that the project dependencies are loaded.   

\section{Implementation}

The development process was split into front-end and back-end. Following the prototype, the front-end pages were created. Bootstrap was added to the HTML to improve the UI design and make it look more appealing for the participants. Furthermore, a hierarchical page set up was implemented by having all HTML pages extending one layout file. This also helped to avoid repeated code as the required libraries were imported only once and all other files inherited them. 

The Express framework was added to the project and the HTML pages were mapped to an Express handlebars or hbs files. Setting up a server in Node.js was very well-documented as Node.js is growing in popularity and there are a number of useful tutorials available on-line. Before implementing the front-end functionality the database system was created and connected to the web application. Then, requests for getting information from the database and sending information to the database were written. Postman was used to check whether the POST and GET requests are working correctly. 

Once it was established that the skeleton of the application is working, Angular was used to do the data binding in the front-end. Angular controllers were set to gather the data for each participant. Then they were sending the information to the back-end in the form of JSON object and from there the JSON data was sent to the database in the form of a database query. For each new participant, there was a participant id created, which was related to their answers to the experimental questions, and the demographic questionnaire. Cookies were used to keep the user ID throughout the experimental session. Latin square was used to randomise the question sequence for each participant. Node.js has a Latin square module which was used to generate the different sequences. Then the matrix sequences were kept in the database and linked to a participant's id ensuring that each user gets a different sequence of questions. Angular was used to populate the website's experimental data - graph images and questions. This was done by using one-page template for all questions and Angular given the required sequence of questions was displaying the appropriate information. 

\subsubsection{Challenges}

Following the implementation, it was found that the front-end structure needs to be changed. Sometimes the size of the large graphs was requiring a scrollbar. This was inconvenient for reading the graphs and it was going to be a confounding variable in the experiment. The size of  the graph had to be kept the same as the rest of the graphs so that the response time is not influenced by the scaled-down image. The bootstrap elements were splitting the page into separate well-defined components: an experimental heading, a remaining time bar, an image section, and a question section. After reviewing which is the necessary information on the page only the graph image and the question were left. This also meant that this particular sequence of pages had to extend a different layout page, which does not contain the navigation bar and has a different Bootstrap grid. Luckily, only one HTML page was used to represent the questions one at a time and it was the only one that had to be changed. In addition, Angular was used to populate the information for the next question after the present one was answered. Therefore, very little alteration had to be made to implement these changes. Thus, the issue of fitting the necessary information on one page was resolved.


\chapter{Experiment}
\label{chap:exp}

\section{Design}

This is a within-subjects design experiment with two conditions. In the first condition, participants answered questions related to causal relationships in node-link graphs, while in the second one they were asked to answer questions on matrix-based representation. Each condition had three factors: size, layout, and question type. There were three levels of the size factor: small (nodes=10), medium (nodes=20), and large (nodes=30). The layouts of the node-link graphs were hierarchical, parallel, and organic. The matrix-based graphs' layouts were in-degree descending, out-degree descending, and alphabetical. The two question types were path questions and direct questions. They represented the two types of tasks in this experiment. In addition, there were three different question themes. The dependent variables were time taken to answer each question and correctness of the answer. The participants were also given a questionnaire which required subjective answers about their graph preferences and how they enjoy solving logical problems. 

\section{Stimuli}

To prepare the experimental stimuli, a variety of graph factors had to be addressed. First, the information complexity in all graphs had to be the same to avoid influencing performance time. Node-link graphs were created in yEd 3.16.1 and then converted into matrix-based representations using an XGML translation software created in Glasgow University. This is how equally complex node-link and matrix-based representations were created. As long as the graphs were from the same domain question and size, they represented the same information. However, each question was carefully structured to require different information to be read from the graphs to avoid learning effect. 

Furthermore, in order to create a large number of graphs, three different question themes were introduced: drinking issues, exams, and healthy/unhealthy gym behaviour. To gain a deeper understanding of which are the most influential characteristics of a graph different layouts and sizes were also implemented. The three different sizes were small, medium, and large. A small node-link graph consisted of 10 vertices and 10 or 9 edges (Figure \ref{sportSmallOrganicS}). The equivalent matrix-based representation had 10 rows, 10 columns and 10 or 9 darker squares showing the causal relationships between the factors (Figure \ref{studentSmallInDDS}). The medium size representations had 20 factors or 20 vertices (node-link graphs) and 20 row and columns (matrix-based graph). The large graphs had 30 variables or 30 vertices in node-link graphs and 30 row and columns in matrix representations. All graphs used in the experiment can be found in Appendix \ref{expStim}.

\begin{figure}[tbp]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{images/sportSmallOrganic.jpg}
    \caption{Small Node-link Graph}
	\label{sportSmallOrganicS}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{images/studentSmallInDD.PNG}
    \caption{Small Matrix-based Graph}
	\label{studentSmallInDDS}
  \end{minipage}
\end{figure}

For each type of representation different layouts were implemented. The matrix-based layouts were alphabetical, in-degree descending and out-degree descending (Figure \ref{matrixLayout}). The alphabetical layout sorts the row and column factors in alphabetical order. The in-degree descending layout finds the number of edges that are coming into each vertex and sorts them in descending order. The out-degree descending layouts calculates the number of edges going out of each vertex and applies descending order.  The node-link layouts were hierarchical, organic, and series-parallel (Figure \ref{nodeLayouts}). yEd applies an algorithm for the creation of each layout. The hierarchical layout represents precedence relation in directed graphs. Series-parallel graphs have one sink and source which are created recursively to generate the series-parallel graph. The organic layout has well-balanced spread out distribution of nodes. Figure \ref{experimentalDesign} shows the pattern which was followed to create 36 graphs with an equal amount of combinations of sizes, layouts and question domains. 

\begin{figure}[h]
\centering
\includegraphics[width=18cm]{images/matrixLayout.png}
\caption{Matrix Layouts}
\label{matrixLayout}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=15cm]{images/nodeLayouts.png}
\caption{Node-link Layouts}
\label{nodeLayouts}
\end{figure}

There was a direct relationship question and an indirect causal relationship question asked for each of the created graphs. The direct question was requiring the participant to answer a question of the type "Factor X is causing which of the following factors" followed by four multiple choice answers only one of which was correct. The path question was asking which of the following causal relationships is correct, followed by four multiple choice answers of the type "factor A $->$ factor B $->$ factor C". The first six questions of the experiment were training questions which did not count towards the final results. The characteristics of the graphs in these questions were chosen to be different from the graphs in the experimental questions. They were added to the beginning of the experiment which generated a total of 42 questions.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{experimentalObjects.png}
\caption{The pattern followed for the creation of the experimental stimuli}
\label{experimentalDesign}
\medskip
\small
Each size of node-link and matrix-based graph was visualised in three different layouts. To enable the generation of different questions, there were 3 question themes: drinking issues (blue), student issues (yellow), and gym issues (purple). Each layout was linked to a theme in the pattern above.
\end{figure}

The specified sequence of questions with matched layouts, question themes, and different sizes was likely to influence the results of the experiment because of the exposure effect of that particular sequence. Therefore, to ensure that all participants receive the questions in a different order, Latin square \cite{winer1962latin} randomization was used. The sequence of questions was different for each participant and the possibility of the questions sequence affecting the results was eliminated.
  
All representations were displayed in their real size on the left side of the screen and the corresponding question was on the right. A special attention was paid to the letter's font-size and retaining the original size of the image on one screen. Participants were not able to go to the next question before they had answered the current one. In addition, to measure answer time more accurately, there was no "Next" button. Once a participant clicked on an answer it was automatically submitted and the next question was loaded on the page. Figure \ref{exampleQuestion} in Appendix C shows an example of a trial question in the web application.

Finally, a Google Form questionnaire was used to ask participants to reflect back on their experience. Two weeks after the testing has started the participants were sent an email with the subjective questionnaire about their graph preference. 

\section{Participants}
There were 30 participants who took part in the experiment, aged between 20 and 29 years. The excluding criteria restricted people specialised in the subjects of Maths, Engineering and Computing Science from participating. The reason for this is that these fields are likely to include preparation in reading graphs. In addition, findings are expected to be representative for the Health and Social sector employees, who are not likely to have previous knowledge in those degrees.

\section{Procedure}

In order to have a better-controlled experiment, the study was conducted only on the experimenter's laptop in their presence. The participants were asked to sit on a chair and complete the experiment in a calm environment. They were recruited either in Glasgow University library or by posts on social media websites. The experiment was conducted in GU library in quiet group study areas. The participants had to read through an information sheet (Appendix \ref{informationsheet}), explaining what was to follow in the next 30 minutes, a consent from (Appendix \ref{consent}), asking them to give their written informed consent, and a training (Appendix \ref{train}) showing them examples of how to solve the upcoming 42 research questions. At the end of the experiment, participants were shown a short demographic questionnaire (Appendix \ref{questionnaire}) and a debrief form (Appendix\ref{debrief}). Two weeks after the testing has started they received another questionnaire asking about their graph preferences (Appendix \ref{preference}).


\section{Pilot}

Conducting a pilot was an essential part of this study. It brought light into how people who have never been exposed to the graphs and the software before interact with them. It was important to learn whether the tasks were clear and the software was easy to use. Three volunteers took part in the pilot. They were asked to sit on a chair in a quiet environment and complete the experiment starting from the information sheet and finishing with the debrief form. At the end, the participants were asked questions regarding the training, the clearness and enjoyment of the tasks. All participants said that the training in the beginning of the experiment is sufficient at explaining how to read the graphs. One of the participants, however, required confirmation that the correct direction of reading the graphs is from left to top. Thus, it was decided to make the first three questions trials in which the participants can ask as many questions as they need to understand how to read the graphs. The second three questions (4,5,6) were also going to be practice questions but they were not going to be explicitly informed about it. Consequently, during the first six tasks, the participants were expected to learn how to interpret the graphs and their answers were not recorded in the results. 

An interesting problem regarding the nature of the trial questions was also considered. Initially, it was suggested that the trial instances are always the first questions of each sequence. However, as those questions would not be accounted for in the results and the Latin Square randomises each sequence, this was going to lead to a uneven number of answers for each type of graph. If this was to happen, the results of the experiment were going to be negatively influenced. In order to avoid this, 6 new questions were created using a combination of layouts, sizes and domains that has not been used for the original 36 questions. A mixture of different sizes and types was included to ensure that the participants have exposure to the main challenges of the experiment during the practice trials. These 6 questions were going to be added at the beginning of each sequence so that all participants are exposed to the same trial questions.  

All participants in the pilot said that the tasks are clear, the graphs' font size is readable, and different layouts and sizes are appropriately displaying the data. One participant mentioned that in the node-link organic layout, the label is on the arrow which makes it hard to read. The reason for this is that both labels and arrows are in black colour. Their note was taken into consideration but if changes are made to align the arrow and the label differently this would alter the organic yEd layout. Consequently, the results will provide information about a manually created layout similar to the organic yEd layout. Another solution to this issue was to change the label names to individual letters like "A" instead of actual factor labels such as "depression", and "pass exams". However, this was going to influence the complexity of the experiment and the participant's level of interest. Thus, no changes were made to the organic layout.  

One volunteer in the pilot mentioned that sometimes it is hard to find the label you are looking for and they guessed the answer to the question by logical reasoning. To avoid this problem in the experiment, a note was made to inform participants that there is no logical relationship between the causal relationships and they should not attempt to guess the correct answer. This is supposed to encourage them to look for the labels rather than guess the correct answer. 

The pilot was also extremely helpful for spotting technical issues. If it was not conducted and some of these problems were not accounted for, the recorded results would have been incorrect. First, it was found that in one question the correct answer was being evaluated to incorrect because of a typo in the CSV file that was used to populate the database. In addition, the answers were not written in a consistent way, which meant that the participants might have been influenced to choose the answer that is written differently from the rest of the answers. In order to fix these problems, the database table with the questions had to be altered. 

Another technical issue found was concerned with the time recorder. It was found that the timing was starting and stopping when required, but the record of the time taken for a particular question was wrong. The issue was found to be caused by a wrong startTime variable during the timeTaken calculation. This was a scope issue, which was fixed for the real experiment. Moreover, in order to submit their answers the participants had to click a "Next" button. The timer used to stop once this button is clicked, the time taken for the current answer was recorded, and start the timer for the next question. However, it was found that this extra click influences the recorded time and it would be more appropriate to have the time start and stop when the participants choose an answer. This led to the decision to completely remove the "Next" button and submit the answers when one of the radio buttons has been selected. On that click the next graph and question would be loaded. It was not expected from the participants to expect a submission of their answer on their first click so thorough instructions about this feature were added in the information sheet. In addition, they were to have six trial questions to get used to that functionality. 
 
In general, the pilot helped in identifying small issues regarding the graphs layout and the manner in which questions were asked. Other bigger issues, that were going to influence the results, were also found such as typos leading to wrong evaluation of correctness and inaccurate time recorder. The pilot also inspired a new way in which the trial questions should be created and accounted for.

\section{Results}

\subsection{Data Analysis Methodology}

Correct data analysis is vital for the successful completion of a research based project. This is why a pilot of the data analysis methodology with fake data was completed before all participants were tested. In order to achieve this the results of 20 participants were faked. As this is a repeated-measures experiment the data layout had to be in wide format with each participant's data represented on each row. However, the way the database was being populated was in long format. Therefore, data wrangling had to be applied before the data was in a format able to be statistically analysed. The data analysis was done with RStudio which provides a package for data wrangling. However, as there were a number of different factors defining each answer and thousands of lines of raw data, it was decided that writing SQL queries would be a more appropriate and easier way to fix the data layout. For each type of comparison, there was a query written to aggregate the needed information in a format ready to be inserted in RStudio. 

Testing the data for outliers was the first part of the analysis. Then, Shapiro-Wilks Normality test was conducted to check whether the data is normally distributed. The test showed a p-value of less than 0.05 for the fake data which rejected the Null hypothesis that the data is normally distributed. Histograms were plotted using the hist() function. This was found to be helpful to visualise the distribution of the values. If the data values were normally distributed then a repeated measures t-test was going to be run to check whether there is a significant difference between the time taken to read the two types of graphs. However, as the data was found to not be normally distributed, a non-parametric test was applied. The non-parametric equivalent of repeated measures t-test is Wilcoxon. 

The type of representation may be the main aspect being investigated, but there are other characteristics of the graph that might influence performance. In order to investigate whether layout and size have any effect, a different statistical test had to be used. For non-parametric data this test is Friedman followed by post-hoc comparison in case of significant difference. The data was faked so that a significant result was found and there was a need to investigate which are the pairs of comparisons significantly different from each other. A function called friedmanmc() was found to compute this comparison, but it returned True or False, not the actual p-value. Therefore, a new function was found but inconsistency in the results of the two functions was found. After a deeper investigation, it was concluded that the second function was not calculating the adjusted p-value which was leading to a difference in results. In order to account for this Bonferroni adjustment was added as a parameter to the calculation. This is how the process for calculating significance between 3  non-parametric factors was finalised. 

The fake data analysis took longer than expected due to the unforeseen circumstances of data wrangling, inexperience with RStudio, and analysis of many different factors. However, because of this process, a clear layout of the analysis for the real data was prepared. All steps of the process were clear beginning with SQL queries to aggregation of data, inserting data in RStudio, and running all statistical tests.

\subsection{Experimental Results}

The data analysis was first done for direct questions and then for path questions. The analysis was split into these groups, as they were two separate tasks requiring different type of computation and different time. Considering that the direct and the path question were two different tasks the participants had to complete, the data was split into two independent parts. There were only 6 incorrect answers in the data in total so the correctness factor was not included in the analysis.

\bigskip
\bigskip

\subsubsection{Direct Questions}

\begin{wrapfigure}{r}{0.35\textwidth}
	\centering
	\vspace{-20mm}
	%\hspace{-8mm}
    \includegraphics[width=0.35\textwidth]{images/directComparison.PNG}
    \caption{Matrix vs Node-link Direct Question} 
	\label{directComparison}
\end{wrapfigure}


A thorough data analysis of all different factors of the graphs was conducted. The results showed that regardless of the graph layout and size the matrix-based graphs (M = 14.15) have better performance than node-link graphs (M = 16.85) for direct questions (Fig\ref{directComparison}) with p-value = 0.0128 (Table\ref{directResults}). When different sizes of each graph type were compared a significant difference was found only for the large graphs comparison with matrix-based large graphs (M = 16.03) being easier to read than node-link graphs (M = 24.76). A Wilcoxon test revealed that p-value = 5.633e-07. Figure\ref{directComparison} shows the mean values of each comparison group. 

\bigskip
\begin{figure}[!ht]
    \includegraphics[width=13cm]{images/nodelinkdirectlayouts.PNG}
    \vspace{-15pt}
    \centering
    \caption{Direct Question: Node-link layout comparison in all size groups}
	\label{nodelinkdirectlayouts}
\end{figure}

Node-link layouts were compared in each size group. Figure \ref{nodelinkdirectlayouts} illustrates the difference in mean values in all node-link layouts and sizes. In small size, the parallel layout was found to have the worst performance (M = 14.20) and hierarchical layout was found to have the best performance (M = 9.65). Friedman test showed that p-value = 0.0013* with significant post-hoc tests between all pairs (Table\ref{directResults}). In the medium size measures, the parallel layout had the worst performance time of 15.62 on average, but when Friedman test was conducted no statistical difference between the three layouts was found with p-value = 0.6575. The node-link large size performance time for hierarchical (M=17.96), parallel (M=38.86), and organic (M=17.46) layouts \ref{nodelinkdirectlayouts} was significantly different and has a p-value = 3.261e-06*. 

The matrix-based based graphs were not found to have consistent performance differences between the various layouts when direct question was asked. A significant difference was found in the medium size with out-degree descending layout (M=12.70) outperforming in-degree descending (M=14.64) and alphabetical layouts (M=14.86). As far as the small and the large sizes are concerned p-value was shown to be insignificant.


\begin{table}[H]
\centering
\caption{Direct Question comparisons}
\label{directResults}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{\textbf{Matrix}}     & \multicolumn{3}{c|}{\textbf{Node-link}} & \textbf{P-value}              \\ \hline
\multicolumn{3}{|c|}{14.15}               & \multicolumn{3}{c|}{16.85}              & 0.0128*                       \\ \hline
\multicolumn{3}{|c|}{small 10.78}         & \multicolumn{3}{c|}{small 11.92}        & 0.1055                        \\ \hline
\multicolumn{3}{|c|}{medium 14.06}        & \multicolumn{3}{c|}{medium 14.01}       & 0.8776                        \\ \hline
\multicolumn{3}{|c|}{large 16.03}         & \multicolumn{3}{c|}{large 24.76}        & 5.633e-07*                    \\ \hline
\multicolumn{3}{|c|}{\multirow{12}{*}{\cellcolor{gray}}}  & \multicolumn{3}{c|}{small}                                            &\cellcolor{gray} \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H 9.65      & P 14.20     & O 11.97     & 0.0013*                       \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H           & P		      &\cellcolor{gray}	& \textless2e-16*               \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & \cellcolor{gray}		& P    		  & O           & 1.8e-09*                      \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H    	&\cellcolor{gray} & O           & 3.5e-05*                      \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & \multicolumn{3}{c|}{medium}                                            &\cellcolor{gray} \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H 14.20     & P 14.62     & O 13.19     & 0.6575                        \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & \multicolumn{3}{c|}{large}                                             &\cellcolor{gray} \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H 17.96     & P 38.86     & O 17.46     & 3.261e-06*                    \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & \cellcolor{gray} & P    & O           & \textless2e-16*               \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H           & P	&\cellcolor{gray}    & \textless2e-16*               \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H           & \cellcolor{gray} & O    & 0.001*                        \\ \hline
\multicolumn{3}{|c|}{small}               & \multicolumn{3}{c|}{\multirow{9}{*}{\cellcolor{gray}}}  &                              \cellcolor{gray} \\ \cline{1-3} \cline{7-7} 
inDD 10.35   & outDD 9.25   & alpha 12.75 & \multicolumn{3}{c|}{\cellcolor{gray}}                   & 0.07939                       \\ \cline{1-3} \cline{7-7} 
\multicolumn{3}{|c|}{medium}              & \multicolumn{3}{c|}{\cellcolor{gray}}                   &                              \cellcolor{gray} \\ \cline{1-3} \cline{7-7} 
inDD 14.64   & outDD 12.70  & alpha 14.86 & \multicolumn{3}{c|}{\cellcolor{gray}}                   & \multicolumn{1}{l|}{0.03943*} \\ \cline{1-3} \cline{7-7} 
inDD         & {outDD} &\cellcolor{gray} & \multicolumn{3}{c|}{\cellcolor{gray}}                   & \multicolumn{1}{l|}{2.4e-10*} \\ \cline{1-3} \cline{7-7} 
\cellcolor{gray}& outDD & alpha       & \multicolumn{3}{c|}{\cellcolor{gray}}                   & \multicolumn{1}{l|}{7.5e-07*} \\ \cline{1-3} \cline{7-7} 
inDD &\cellcolor{gray} &  alpha       & \multicolumn{3}{c|}{\cellcolor{gray}}                   & \multicolumn{1}{l|}{0.12}     \\ \cline{1-3} \cline{7-7} 
\multicolumn{3}{|c|}{large}               & \multicolumn{3}{c|}{\cellcolor{gray}}                   & \multicolumn{1}{l|}{\cellcolor{gray}}         \\ \cline{1-3} \cline{7-7} 
inDD 15.34   & outDD 14.76  & alpha 18.00 & \multicolumn{3}{c|}{\cellcolor{gray}}                   & \multicolumn{1}{l|}{0.355}    \\ \hline

\end{tabular}
\end{table}

H - hierarchical; P - parallel; O - organic; inDD - in-degree descending; outDD - out-degree descending; alpha - alphabetical

\subsubsection{Path Questions}

\begin{wrapfigure}{r}{0.35\textwidth}
	\centering
	\vspace{-10mm}
	%\hspace{-8mm}
    \includegraphics[width=0.35\textwidth]{images/pathComparison.PNG}
    \caption{Matrix vs Node-link} 
	\label{pathComparison}
\end{wrapfigure}

The path question results showed a different pattern. The Wilcoxon comparison between the matrix-based (M=35.62) and node-link (M=31.81) representations of all sizes and layouts showed a significantly better performance for node-link graphs \ref{pathComparison} with p-value=0.02479*. In the small group size of this question type, matrix-based representations (M=23.09) were outperformed by node-link graphs (M=27.83). Wilcoxon test reported a p-value of 0.03997* (Table\ref{pathResults}). No difference was found in the medium size graphs but in the large size group matrix-based graphs (M=47.38) showed worse performance than node-link graphs (M=39.51). Wilcoxon test showed a p-value of 0.02847*. 

The node-link layout comparison showed that for small sizes the hierarchical layout (M=27.31) has the worst performance, followed by the parallel layout (M=22.43) and the organic layout (M=19.62). Friedman test found a significant difference between the layouts with p-value=5.943e-06*. However, in the medium size group, the layouts showed different results (Figure\ref{nodePathLayouts}). The organic layout (M=48.55) performed significantly worse than the parallel (M=26.44) and the hierarchical (M=23.54) (Figure \ref{pathResults}). These results were consistent with the large size group layouts where the organic layout (M=47.88) showed worse performance than parallel (M=39.20) and hierarchical (M=31.44) layouts.

\begin{figure}[H]
\centering
\includegraphics[width=13cm]{images/nodePathLayouts.PNG}
\caption{Path Question: Node-link layout comparison in all size groups}
\label{nodePathLayouts}
\end{figure}

Among the matrix layouts, significant difference was found in the small and large size groups. When the size is small, alphabetical layout (M=23.79) outperformed out-degree descending (M=29.50) and in-degree descending (30.20) layouts \ref{matrixpathlayouts}. A Friedman test found a significant difference between the three layouts with p-value=0.0003245*. In the medium size group, the alphabetical layout was confirmed to have the best performance (M=27.29) when compared to in-degree descending layout (M=29.07), but no statistical difference was found when compared to out-degree descending layout (M=28.68) with p-value=0.26. No significant difference was found among the layouts in large size. All p-values for path question can be found in Table \ref{pathResults}.

\begin{figure}[H]
\centering
\includegraphics[width=13cm]{images/matrixpathlayouts.PNG}
\caption{Path Question: Matrix-based layout comparison in all size groups}
\label{matrixpathlayouts}
\end{figure}

\begin{table}[H]
\centering
\caption{Path Question comparisons}
\label{pathResults}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{\textbf{Matrix}}     & \multicolumn{3}{c|}{\textbf{Node-link}} & \textbf{P-value} \\ \hline
\multicolumn{3}{|c|}{35.62}               & \multicolumn{3}{c|}{31.81}              & 0.02479*         \\ \hline
\multicolumn{3}{|c|}{small 27.83}         & \multicolumn{3}{c|}{small 23.09}        & 0.03997*         \\ \hline
\multicolumn{3}{|c|}{medium 31.67}        & \multicolumn{3}{c|}{medium 32.85}       & 0.2665           \\ \hline
\multicolumn{3}{|c|}{large 47.38}         & \multicolumn{3}{c|}{large 39.51}        & 0.02847*         \\ \hline
\multicolumn{3}{|c|}{\multirow{15}{*}{\cellcolor{gray}}}  & \multicolumn{3}{c|}{small} & \cellcolor{gray}                                 \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H 27.31      & P 22.43     & O 19.62    & 5.943e-06*       \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H            & P &\cellcolor{gray}  & 4.5e-12*         \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    &\cellcolor{gray} & P     & O          & 4.5e-12 *        \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H            & \cellcolor{gray} & O   & \textless 2e-16* \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & \multicolumn{3}{c|}{medium}  &\cellcolor{gray}                              \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H 23.54      & P 26.44     & O 48.55    & 3.08e-09*        \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H            & P &\cellcolor{gray}   & 2.40e-13*        \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H & \cellcolor{gray}     & O          & \textless 2e-16* \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & \cellcolor{gray} & P     & O          & \textless 2e-16* \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & \multicolumn{3}{c|}{large} & \cellcolor{gray}                                 \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H   31.44    & P   39.20   & O  47.88   & 0.0273*          \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & \cellcolor{gray} & P     & O          & 1.1e-09*         \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H            & P & \cellcolor{gray}   & 1                \\ \cline{4-7} 
\multicolumn{3}{|c|}{\cellcolor{gray}}                    & H & \cellcolor{gray}     & O          & 1.1e-09*         \\ \hline
\multicolumn{3}{|c|}{small}               & \multicolumn{3}{c|}{\multirow{12}{*}{\cellcolor{gray}}} & \cellcolor{gray}                 \\ \cline{1-3} \cline{7-7} 
inDD 30.20   & outDD 29.50  & alpha 23.79 & \multicolumn{3}{c|}{\cellcolor{gray}}                   & 0.0003245*       \\ \cline{1-3} \cline{7-7} 
inDD         & outDD & \cellcolor{gray} & \multicolumn{3}{c|}{\cellcolor{gray}}                   & 1.0e-09*         \\ \cline{1-3} \cline{7-7} 
\cellcolor{gray} & outDD & alpha       & \multicolumn{3}{c|}{\cellcolor{gray}}                   & \textless 2e-16* \\ \cline{1-3} \cline{7-7} 
inDD    &\cellcolor{gray}     & alpha & \multicolumn{3}{c|}{\cellcolor{gray}}                   & 1.7e-07*         \\ \cline{1-3} \cline{7-7} 
\multicolumn{3}{|c|}{medium}              & \multicolumn{3}{c|}{\cellcolor{gray}}                   & \cellcolor{gray}                 \\ \cline{1-3} \cline{7-7} 
inDD 39.07   & outDD 28.68  & alpha 27.29 & \multicolumn{3}{c|}{\cellcolor{gray}}                   & 0.001454*        \\ \cline{1-3} \cline{7-7} 
inDD         & outDD & \cellcolor{gray} & \multicolumn{3}{c|}{\cellcolor{gray}}                   & 4.5e-13*         \\ \cline{1-3} \cline{7-7} 
inDD & \cellcolor{gray} & alpha       & \multicolumn{3}{c|}{\cellcolor{gray}}                   & 7.7e-16*         \\ \cline{1-3} \cline{7-7} 
\cellcolor{gray} & outDD & alpha       & \multicolumn{3}{c|}{\cellcolor{gray}}                   & 0.26             \\ \cline{1-3} \cline{7-7} 
\multicolumn{3}{|c|}{large}               & \multicolumn{3}{c|}{\cellcolor{gray}}                   &\cellcolor{gray}                  \\ \cline{1-3} \cline{7-7} 
inDD 45.45   & outDD 48.93  & alpha 47.7  & \multicolumn{3}{c|}{\cellcolor{gray}}                   & 0.356            \\ \hline
\end{tabular}
\end{table}
H - hierarchical P - parallel O - organic inDD - indegree descending outDD - outdegree descending alpha - alphabetical

\subsection{Summary}

Direct Question:
\begin{itemize}
 \itemsep0em
	\item Matrix-based graphs were found to have better performance than node-link graphs for direct questions.
	\item The parallel layout had worst performance in all sizes.
	\item The hierarchical layout was the best in small node-link graphs, while for large size the organic layout was the best performing one.
	\item In matrix-based layouts, significant difference was found only in medium size, with the out-degree descending layout being the best performing one.
\end{itemize}
Path Question:
\begin{itemize}
\itemsep0em
	\item Node-link graphs had better performance than matrix-based graphs in the path question task.
	\item In the small size comparison for node-link layouts, organic representations were found to be the best performing ones.
	\item In the layout comparison for medium and large size, the hierarchical layout was found to outperform the rest of the layouts.
	\item In the matrix-based representations, alphabetical layout was found to be the best performing one in small and medium graphs.
	\item When large layouts were compared no difference in performance was found.
\end{itemize}


\section{Preference Results} 

The participants' answers to the preference questionnaire brought more light into their graph preference and experience during the experiment. It was found that the majority of people (80\%) would prefer to work with node-link graphs. On the question asking how easy they found working with node-link graphs the participants reported an average of 2 (1="Very easy", 5="Very hard") while for the matrix-based representation an average rating of 2.9 was found. These findings suggest that on average people found working with node-link graphs easier which is consistent with the results for graph preference. On the question whether they enjoy solving logical problems the participants scored an average of 3.8 (1="Not at all" and 5="Very much"). Their liking for Maths on the same scale was averaged to 3.3 meaning that the participants had a positive attitude towards problem solving and mathematics. On the last question of whether there was something stopping them from performing at their best most people said "No". However, some participants said that they had issues finding the label they were looking for, some mentioned that they might have experienced difficulties paying attention, while one person just said that they did not find the task particularly interesting. One participant mentioned that the location of the experiment was an issue as there was noise in the environment that was preventing them concentrating properly. Even though the experiment was conducted in the library's quiet area, there were people unaware that different levels of the library require different behaviour, and caused concentration difficulties for this one participant.


\section{Qualitative Results}

The experiment was done in the presence of the researcher to ensure high validity of the results and also to allow for  observations while the participants were doing the tasks. For example, while one of the participants was working on the tasks their telephone rang and they got distracted from the tasks. However, a timer was started to measure how long it took the participant to come back to the tasks and then this time was subtracted from the total recorded time for this question. An additional issue which arises is that it is impossible to measure whether the participant had to read the question again when they came back from their distraction or they were able to continue from where they stopped. Fortunately, this happened only once, and the time before the distraction was added on to the time after the distraction.

In general, there was a positive feedback about the questions asked and the nature of the topics. Most people found them very familiar and were interested to find the causal relationships. A few people (N=3) mentioned that the font-size of the labels was small and it was difficult to follow the matrix row and columns on the large graphs because of the small size of the squares. The squares and font-size were made as large as possible, but due to the big amount of information that had to be fitted on one screen, some participants still experienced difficulties. One of these participants said that it might have been more difficult for them as they have eyesight issues. Other participants were explicitly asked after the experiment whether they had experienced any issues and they reported that everything was fine.

\chapter{Discussion}

The experimental findings showed that for direct questions matrix graphs have better performance than node-link graphs, but for path questions the opposite was true - node-link graphs outperformed matrix-based representations. Direct questions required the participants to find a label and check which factor is being caused by this label. The results of the experiment suggested that it was easier for the participants to find this label on the matrix-based graph. Considering the layouts of the two representations, the matrix has a row and a column while the node-link layout is rather spread out and unevenly distributed on the screen. Consequently, a possible explanation for the better performance of matrix-based graphs for direct questions can be that it is easier for the human eye to find a label in a row rather than on a flat space where factors are spread out in different directions. 

When path questions were concerned node-link graphs outperformed matrix-based graphs. In order to answer a path question in matrix-based graph, two selected cells had to be found, which could be positioned in two completely different locations in the matrix. Therefore, it would take time for the participant to find these two cells. For node-link graphs, however, the participants were required to follow the link between nodes that are positioned next to each other. Therefore, they had to spend time finding only one of the factors. Our results confirmed the findings of Zekian et al \cite{sheny2007path}, who also concluded that node-link representations are better than matrix-based graphs when answering path questions for causal visualisations. In addition, we supported the findings of Ghoniem and colleagues \cite{ghoniem2004comparison} that node-link graphs outperform matrix-based graphs in path questions.

The layout analysis did not find a consistent best performing layout in node-link and matrix-based graphs. However, a consistent worst performing layout depending on the size of the graph and type of representation was found. First, in node-link direct questions, the parallel layout was found to take significantly more time to read than the rest of the layouts (Fig.  \ref{nodelinkdirectlayouts}). A deeper investigation revealed that a possible reason for these findings is that the edge length in the parallel layout is longer than the rest of the layouts. To illustrate the difference between layouts, edge length in the causal path in the "small drinking issues" graph between the factors "drinking parents", "early age drinking", and "depression" was measured. The edge length in the hierarchical layout was 2.9cm, and the edge length in the organic layout was 3cm, while the length in the organic layout was 11.9cm. In order to show the difference between the layouts an example that shows the biggest difference in length in this particular graph was chosen. It must be noted that the length difference is not that large in all causal relationships. The graphs were generated by a yEd algorithm and it was out of our control to account for edge lengths. What is more, the goal of the experiment was to examine different yEd layouts. However, the edge lengths in the parallel layout varied greatly, while the edge lengths in the hierarchical and parallel layouts were very similar - between 1cm and 1.5cm between two nodes. 

Consequently, it was suggested that the length of the edge is a direct predictor of performance. Furthermore, a controlled experiment examined readability of graphs, while manipulating the length of the edges \cite{holten2011extended}. There were two edge lengths - short and long. It was found that it took participants significantly longer to answer questions on graphs with long edges than on graph with short edges. As a result, this study brings a possible explanation for the bad performance of the parallel layout in the present experiment.

The readability of a node-link graph is characterised by readability metrics. These are means that define the understandability of the graph based on the number of nodes and overlapping edges. A well-known method for inducing better readability of node-link graphs is spreading out the nodes evenly, keeping the edges away from the nodes, and edges-lengths equal, and avoid overlapping \cite{dunne2015readability}. In addition, another experiment investigated which are the most important factors when measuring aesthetics of a graph \cite{purchase1997aesthetic}. It was found that among edge crosses, orthogonality, edge bends, symmetry, and angle maximisation, the most important aesthetic factor was edge crosses. In the present experiment, the parallel layout is the only layout that has any edge crossings. The hierarchical and organic layouts have links between edges that do not cross each other. Therefore, the longer response time in the parallel layout might also be caused by the edge crossings.

Furthermore, it was found that minimization of bends in edges can contribute to a more aesthetically pleasing layout \cite{ware2002cognitive}. In the present experiment, the links between the nodes in the organic layout are always straight lines. The hierarchical layout has a 90 degrees edge to form a hierarchical structure and the parallel layout usually sticks to the same 90 degrees edge. However, sometimes the parallel layout has an unpredictable way of curving a few edges. An example of this can be seen in figure \ref{sportMedParallel} and the shape of the edge pointing from "large gym" to "social gym experience". Therefore, our experiment supports the findings of Ware and colleagues \cite{ware2002cognitive} that edge bendiness is an important factor for the readability of node-link layout.

Interestingly, however, these results were not found in the path questions. There the parallel layout outperformed the organic one. It was found that in the medium and large graphs, the organic layout has significantly worse performance than hierarchical and parallel graphs. There was a big similarity between the mean values of the hierarchical and parallel layout. Thus, the differences between organic layout and hierarchical/parallel were investigated. The organic layout \ref{drinkingIssuesMedOrganic} is spread out in all directions and the direction of the edges does not follow a particular pattern. However, in parallel (Fig. \ref{sportMedParallel}) and hierarchical (Fig. \ref{drinkingIssuesSmallHier}) graphs the nodes are ordered into parallel rows and the edges always point from the upper level to the lower level. Therefore, the direction of the edge is proposed to be another important characteristic of the causal graphs. 

Path questions require the reader to follow two edges which might be the reason why the results are influenced in favour of readability of edge direction, where organic graphs are outperformed by the rest of the layouts. As discussed above the direction of the edge in the organic question is not predefined and the person reading the graph needs to follow each edge, while for hierarchical and node-link graphs the edges are always pointing down. As a result, this could be the reason for the worse performance of the organic layout in path questions.

Matrix-based graphs did not differ significantly in the direct question type for small and large size. A significant difference was found between the layouts in the medium size, with out-degree descending layout having the best performance. In the path question, the alphabetical layout was found to be the best performing one in the small and medium size. No significant difference between layouts was found in the large size. An explanation for the above average performance of the alphabetical layout was expected as the users were able to find the label they are looking for quicker. A preference for alphabetical order of the factors was expressed at the informal observations during the experiment.

Moreover, Bach and colleagues \cite{bach2014visualizing} examined various readability factors in matrix cubes by interviewing two experts in different fields - an astronomer and a neurologist. It was suggested that reordering rows and columns in matrix representations can be confusing. Visual clusters were not found to aid readability by the astronomy expert as they were suggested to prevent the recognition of separate rows and columns. He suggested that an alphabetical order is more appropriate and easier to read. However, according to the neurology expert row and column ordering to form data clusters was better when representing the data than alphabetically ordered matrices. According to this study, the matrix layout needs to be tailored to the user preference and area of expertise.

As a result, matrix-based representations are still not very well understood. Our preference research among the participants showed that people would rather work with node-link graphs. Interestingly, we found that matrix-based graphs had better performance than node-link graphs in the direct question. A possible cause for participants' preference result could be that the matrix is not as user-friendly as the node-link graph and requires training. The matrix results suggest that alphabetical order has the best performance when searching for particular factors. However, as noted by Bach and colleagues \cite{bach2014visualizing} depending on the task and the type of visualised data there could be different best performing matrix orderings. 

\section{Software reusability}

The implemented software can be reused in a different data visualisation experiment without the need to implemented additional changes. As long as the desired functionality is the same, the displayed stimuli, questions asked and multiple choice answers can be changed by altering the database. If the database schema is followed the web application will be able to display any questions with multiple choice answers. The experimental software will be able to record participants' answers in the Answers table as long as it has the same schema. For example, if a follow-up study aims to examine whether performance is influenced by colour coding, the current software can be reused. The researchers will have to alter the database with the colour coded stimuli and if they want they can add more questions or change the questions according to their stimuli. 

Moreover, a completely different data visualisation study can also be conducted with the use of the present experimental software. For instance, it might be an experiment investigating readability of different types of charts. The most efficient way to populate the questions for the new experiment is by importing a CSV file which follows the Questions table schema into the database. A possible issue that might occur is that the visualisations of interest do not have the same description fields. The description fields in the present experiment were question type, layout, and size. In this case, the database schema and the implementation of the requests will have to be changed. However, as this information is only used in the "Participants Answers" section in the website a change in the query requesting information for the population of that specific web-page needs to be made.  

Thus, depending on the experiment that needs to be run on the software it might require either no change in the implementation or slight alterations to the database schema and the logic of the implementation.

\section{Limitations and Future work}

\subsection{Experimental Software}

To improve the reusability of the web application, an extra layer of complexity can be added to the experimental software. This is an Admin interface which will give the experimenter more flexibility when creating an experiment. For example, at the moment the Latin square randomization is made for a particular number of participants. A completely flexible experimental software should be able to allow the experimenter to input the number of the participants and have the randomisation done for them.

Additional features of the Admin interface will allow the experimenter to input the questions and answers in a form on the website rather than changing the database manually. Furthermore, the web application was not deployed anywhere, as for this specific experiment the researcher had to be present in order to control for the environmental factors that might influence participants' performance. For future experiments that might not be necessary and particularly if a large number of people need to take part in the experiment, the project needs to be deployed. However, this will lead to a security issue, as the application at the moment does not have different levels of authorisation implemented. The reason for this is that it was supposed to be used only on one the researcher's laptop. Another possible issue that might arise if the application is deployed is scalability of the graph images: they will need to be adjusted for the participants' screens. 

Therefore, the experimental software was used successfully to test the present research question. In order to make it a completely reliable experimental system that can be used on-line, however, more features need to be implemented. There are also important factors, that the researcher needs to consider. Some of these are screen size and the environment in which the participants complete the study.

\subsection{Experimental Question}

The experimental findings brought light into the factors which influence readability in causal relationships in node-link and matrix-based graphs. Our research question was answered successfully, but further investigation in the underlying mechanisms that influenced the results needs to be made. It was found that parallel graphs have the worst performance in node-link direct graphs, and according to previous research, the reason for that is thought to be edge length and edge crossings. However, these are only speculations as the present experiment did not control for either of these factors. Therefore, a future experiment might examine the response time of causal graphs with different edge lengths and number of edge crossings. 

Furthermore, a deeper investigation of the reason why there are different best performing layouts for the two types of questions - direct and path, needs to be made. It is interesting to examine whether we found this difference because we were visualising causal relationships. Future investigation might compare directed and non-directed node-link and matrix-based graphs and evaluate whether the came readability predictors will influence performance.

Matrices are a new way of visualising causal relationships and more research needs to be done evaluating the readability predictors in these visualisations. Matrix-based visualisations were found to found to be better at answering direct questions when compared to node-link graphs. Therefore, they have the potential to replace node-link graphs so further investigation in different row and columns orderings need to be conducted. 

\section{Conclusion}

Causal relationships can be visualised by node-link and matrix-based graphs. Node-link graphs are well-known visualisations used to illustrate directed and non-directed graphs for a long time. However, matrix graphs are a new representation which has recently been involved in visualising causal graphs. The aim of this project was to examine which type of graph is more readable for people. To test that experimental software was implemented using Node.js, Angular and PostgreSQL. Different layouts, sizes, types of questions and question themes were created. Thirty participants were tested in a controlled environment. The results proposed that matrix-based representations have a better response time for direct questions, while node-link graphs have better performance for path questions. These results were related to previous studies which found similar differences between node-link graphs and matrix-based representations for non-directed graphs. Further investigation can examine the similarities in performance between causal and non-directed graphs. It will be interesting to investigate whether the pointing edge of the node-link graph can contribute to the complexity of the graph and significantly slow down human perception.

In a real-life environment, when people working in the Social and Health sector are trying to answer a specific question from a matrix-based or node-link visualisation knowing which is the more efficient way of finding information can help them save time and money. In addition, a data visualisation technique that is not likely to be misread will help them take the correct decisions according to the data. The implications of the results of the present project brought more light into the visualisation of causal relationships and the effectiveness of different layouts.




%%%%%%%%%%%%%%%%
%              %
%  APPENDICES  %
%              %
%%%%%%%%%%%%%%%%
\begin{appendices}

\chapter{Experimental Software}

\section{Home Screen}

\begin{figure}[H]
\centering
\includegraphics[width=14cm]{images/home.PNG}
\caption{This is the home screen. The experimenter can choose whether they would like to conduct an experiment, or see research or demographic data}
\label{homeScreen}
\end{figure}

\section{Information Sheet}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{images/informationsheet.PNG}
\caption{All participants read the Information Sheet before they participated in the experiment.}
\label{informationsheet}
\end{figure}

\section{Consent Form}

\begin{figure}[H]
\centering
\includegraphics[width=14cm]{images/consent.PNG}
\caption{After reading the Information Sheet, participants were asked to agree with the Consent Form}
\label{consent}
\end{figure}

\section{Training}
\label{train}

All participants were provided with video training, which can be found \href{https://youtu.be/pkchO1fafrs}{here}.

They were also given the following written instructions of how to read the graphs.

----------------------------------------------------------------------------------------------------------------------

Node-linked graphs are graphs made of vertices and edges. Those graphs are used to
represent causal relationships between two or more variables. The node-linked graph displayed
in figure 1.2 has two vertices: having fun and good memories, and one edge between them
which points towards good memories. When reading this graph one would say: Having fun
causes good memories.

\begin{figure}[H]
\centering
\includegraphics[width=7cm]{images/training11.PNG}
\caption{}
\label{training11}
\end{figure}

Those graphs are also used to show causal paths or indirect relationships between factors.
For example Figure 1.2 shows that playing games causes having fun which causes good
memories. At the same time playing games causes procrastination, which causes
dissatisfaction. These are two different causal paths. Therefore, playing games indirectly
causes dissatisfaction and good memories.

\begin{figure}[H]
\centering
\includegraphics[width=7cm]{images/training12.PNG}
\caption{}
\label{training12}
\end{figure}

The same information can also be displayed in a matrix-based graph (Figure 1.3). The darker
squares on the matrix show that the row factor (horizontal label, on the left) is causing the
column factor (vertical label, at an angle). For example, playing games (horizontal) causes
having fun (vertical). Then if we are looking for a path we will look for factors that are caused
by having fun. In order to do this we find the having fun factor on the left and will find the
column factor that it is connected with, which is good memories. This way the same causal
path is found: playing games $->$ having fun$ ->$ good memories.

\begin{figure}[H]
\centering
\includegraphics[width=13cm]{images/training13.PNG}
\caption{}
\label{training13}
\end{figure}

To see that one factor can lead to different causal paths, we need to find the row factor that has
more than one darker square. In this example, this is playing games. Please, find the the row
playing games and find what are two different factors that it can lead to. As previously
mentioned those are having fun and procrastination.

If you still have any questions regarding reading how to read those graphs please ask the
researcher in the room for help.
Otherwise, you can proceed to start the experiment.

----------------------------------------------------------------------------------------------------------------------
\section{Demographic Questionnaire}

\begin{figure}[H]
\centering
\includegraphics[width=14cm]{images/questionnaire.PNG}
\caption{Questionnaire}
\label{questionnaire}
\end{figure}


\section{Debriefing form}

\begin{figure}[H]
\centering
\includegraphics[width=14cm]{images/debriefing.PNG}
\caption{Debriefing form was shown to all participants at the end of the experiment.}
\label{debrief}
\end{figure}

\section{Preference Questionnaire}
\label{preference}
The preference questionnaire can be found \href{https://docs.google.com/forms/d/e/1FAIpQLSeEKichG31qd8Ba88OqcTDvYKJLk-Xf8oWBELAJMx0QDHbe-g/viewform?usp=sf_link}{here}.
\section{Research Questions}

\begin{sidewaysfigure}[ht]
\centering
\includegraphics[width=24cm]{exampleQuestion.PNG}
\caption{Example of a path question}
\label{exampleQuestion}
\end{sidewaysfigure}


\begin{sidewaysfigure}[ht]
\centering
\includegraphics[width=24cm]{images/directQ.PNG}
\caption{Example of a direct question}
\label{directQ}
\end{sidewaysfigure}


\chapter{Experimental Stimuli}
\label{expStim}

\section{Matrix-based}

\begin{figure}[H]
\centering
\includegraphics[width=16cm]{images/drinkingLargeInDD.PNG}
\caption{Large matrix-based graph in in degree descending layout and drinking issues domain question}
\label{drinkingLargeInDD}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=16cm]{images/drinkingMedOutDD.PNG}
\caption{Medium matrix-based graph in out degree descending layout and drinking issues domain question}
\label{drinkingMedOutDD}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=16cm]{images/drinkingSmallAlpha.PNG}
\caption{Small matrix-based graph in alphabetical layout and drinking issues domain question}
\label{drinkingSmallAlpha}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=16cm]{images/gymLargeAlpha.PNG}
\caption{Large matrix-based graph in alphabetical layout and sport domain question}
\label{gymLargeAlpha}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=16cm]{images/gymLargeOutDD.PNG}
\caption{Large matrix-based graph in out degree descending layout and drinking issues domain question}
\label{gymLargeOutDD}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=16cm]{images/gymMedInDD.PNG}
\caption{Medium matrix-based graph in in degree descending layout and sport domain question}
\label{gymMedInDD}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=16cm]{images/gymSmallAlpha.PNG}
\caption{Small matrix-based graph in alphabetical layout and sport domain question}
\label{gymSmallAlpha}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=16cm]{images/gymSmallOutDD.PNG}
\caption{Small matrix-based graph in out degree descending layout and sport domain question}
\label{gymSmallOutDD}
\end{figure}



\begin{figure}[H]
\centering
\includegraphics[width=15cm]{images/studentMedAlpha.PNG}
\caption{Medium matrix-based representation in alphabetical layout and student domain question}
\label{studentMedAlpha}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=15cm]{images/studentSmallInDD.PNG}
\caption{Small matrix-based representation in in degree descending layout and student domain question}
\label{studentSmallInDD}
\end{figure}

\section{Node-link}

\begin{sidewaysfigure}[ht]
\centering
\includegraphics[width=20cm]{images/drinkingIssuesLargeParallel.jpg}
\caption{Large node-link graph in parallel layout and drinking issues domain question}
\label{drinkingIssuesLargeParallel}
\end{sidewaysfigure}

\begin{figure}[H]
\centering
\includegraphics[width=15cm]{images/drinkingIssuesMedOrganic.jpg}
\caption{Medium node-link graph in organic layout and drinking issues domain question}
\label{drinkingIssuesMedOrganic}
\end{figure}


\begin{sidewaysfigure}[ht]
\centering
\includegraphics[width=18cm]{images/studentMedHier.jpg}
\caption{Medium matrix-based graph in hierarchical layout and student domain question}
\label{studentMedHier}
\end{sidewaysfigure}


\begin{figure}[H]
\centering
\includegraphics[width=12cm]{images/drinkingIssuesSmallHier.jpg}
\caption{Small node-link graph in hierarchical layout and drinking issues domain question}
\label{drinkingIssuesSmallHier}
\end{figure}


\begin{sidewaysfigure}[ht]
\centering
\includegraphics[width=19cm]{images/sportLargeHier.jpg}
\caption{Large node-link graph in hierarchical layout and sport domain question}
\label{SportLargeHier}
\end{sidewaysfigure}


\begin{sidewaysfigure}[ht]
\centering
\includegraphics[width=16cm]{images/sportMedParallel.jpg}
\caption{Medium node-link graph in parallel layout and sport domain question}
\label{sportMedParallel}
\end{sidewaysfigure}

\begin{figure}[H]
\centering
\includegraphics[width=10cm]{images/sportSmallHier.jpg}
\caption{Small node-link graph in hierarchical layout and sport domain question}
\label{sportSmallHier}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=10cm]{images/studentSmallParallel.jpg}
\caption{Small node-link representation in parallel layout and student domain question}
\label{studentSmallInDD}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=10cm]{images/sportSmallOrganic.jpg}
\caption{Small node-link graph in organic layout and sport domain question}
\label{sportSmallOrganic}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{images/studentLargeOrganic.jpg}
\caption{Large node-link graph in organic layout and student domain question}
\label{studentLargeOrganic}
\end{figure}

\chapter{Progress Diary}

Here is a summary of the achievements for each month.

{\bfseries September}
\begin{itemize}
	\item Research in data visualisation and causal relationships.
\end{itemize}

{\bfseries October}
\begin{itemize}
	\item Aims of the project were established: matrix-based vs node-link comparison.
	\item The software for creating the visualisation stimuli was chosen.
	\item Different ways to implement the experimental software were discussed.
	\item Requirements and user stories.
	\item Research in different matrix-based and node-link layouts.
	\item The technology tools that were going to be used in the project (Node.js, Angular and PostgreSQL) were chosen. 
\end{itemize}

{\bfseries November}
\begin{itemize}
	\item Node-link and matrix-based graphs were created for the experimental questions.
	\item Web application development was initialised.
	\item The decision to have two types of tasks (direct question and path question) was taken.
	\item Information sheet, consent form and training video were completed.
	\item Latin square was added to the web application.
	\item All questions were added to the database.
	\item The pilot of the experiment started.
	\item The draft of the Implementation section was written.
\end{itemize}

{\bfseries December}
\begin{itemize}
	\item Issues spotted in the Pilot were fixed and the experiment was ready for real testing.
	\item The first participant took part in the experiment.
	\item Drafts of the Experimental methodology and Pilot section were written.
\end{itemize}

{\bfseries January}
\begin{itemize}
	\item The results analysis methodology was established.
	\item 30 participants completed the experiment.
\end{itemize}

{\bfseries February}
\begin{itemize}
	\item The experimental data was analysed.
	\item Results section was written.
\end{itemize}

{\bfseries March}
\begin{itemize}
	\item Introduction Chapter and Literature Background Chapter were finalised.
	\item Discussion chapter was written.
\end{itemize}

\end{appendices}
%%%%%%%%%%%%%%%%%%%%
%   BIBLIOGRAPHY   %
%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{plain}
\bibliography{bib}

\end{document}
